\documentclass[12pt,a4paper,final]{article}
\usepackage[hmargin=2cm,vmargin=2cm,bmargin=2cm]{geometry} % Margem Obrigatoria
\usepackage{pslatex} %times new roman obrigatorio
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage{amsmath}
\usepackage{titling}
%\usepackage[•]{•}kage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
%\graphicspath{{images/}}
%\usepackage{float}
%\usepackage{caption}
\usepackage{floatrow}
\usepackage{multirow}
\usepackage{url}
\usepackage[brazil]{babel} % em portugues brasileiro
\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{color}
\usepackage{cancel}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=t,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=shadowbox,
    tabsize=2
}

\lstset{style=mystyle}
\renewcommand{\lstlistingname}{Listagem}
\newcommand{\blue}{\textcolor{blue}}
\renewcommand{\thesubsection}{\thesection.\Alph{subsection}}
\floatsetup[table]{capposition=top}
\author{Lucas Baganha Galante 182364\\Tiago Loureiro Chaves 187690}

\title{Cálculo Numérico \\ Projeto 1 - Turma D}

\date{2 de Outubro de 2018}

\begin{document}

\onehalfspace %Espaçamento 1.5 obrigatório

\maketitle

% \begin{abstract}
% \end{abstract}

\section{Questão 1}
\textbf{Fazer o projeto 1: ``Precisão da Máquina'',
da página 24 do livro \textit{Cálculo Numérico}, Ruggiero-Lopes, 2a. edição.}

\subsection{}

O algoritmo descrito no exercício foi implementado na linguagem C, por apresentar
variáveis com precisão simples e dupla. A saída contém a precisão de máquina de
cada tipo de variável expressa em 20 casas decimais, como visto na Listagem~\ref{lst:label1}.

\begin{lstlisting}[caption= \textbf{Precisão de máquina para variáveis simples e duplas.},label={lst:label1}]
  The single precision is: 0.00000011920928955078
  The double precision is: 0.00000000000000022204
\end{lstlisting}

A variável com precisão dupla apresenta maior precisão que a variável com precisão
simples; com 16 casas decimais, que compara com 7 casas decimais da precisão simples. Portanto o ganho
é maior que o dobro, como esperado.

\subsection{}

Quando se sai do laço while se perde uma precisão a mais que a precisão de máquina, que é o
motivo para se sair do laço, pois a soma $1+A$ não é maior que $1$, devido a aritmética de ponto
flutuante. Deste modo é necessário multiplicar $A$ por 2, para que se retorne ao menor valor em que
a máquina possui precisão.

\subsection{}

O algoritmo executado na \texttt{Parte A} foi modificado para se utilizar um valor \textbf{VAL} para
inicialização ao invés da referência, o número 1. A saída é vista abaixo na Listagem~\ref{lst:label2}

\begin{lstlisting}[caption= \textbf{Precisão de máquina para diferentes valores VAL.},label={lst:label2}]
  The single precision for VAL:    10.0 is: 0.00000095367431640625
  The single precision for VAL:    17.0 is: 0.00000190734863281250
  The single precision for VAL:   100.0 is: 0.00000762939453125000
  The single precision for VAL:   184.0 is: 0.00001525878906250000
  The single precision for VAL:  1000.0 is: 0.00006103515625000000
  The single precision for VAL:  1575.0 is: 0.00012207031250000000
  The single precision for VAL: 10000.0 is: 0.00097656250000000000
  The single precision for VAL: 17893.0 is: 0.00195312500000000000
\end{lstlisting}

Se percebe da saída que quanto maior o valor de \textbf{VAL} menor se torna
a precisão da máquina. Isso ocorre pois serão necessários
mais dígitos da mantissa para representar na variável de iteração (no algoritmo
atribuída como variável \texttt{s}), o que diminui o número
de dígitos que podem ser usados para determinar a precisão.

\subsection*{Código}

\lstinputlisting[language=C,caption=\textbf{Base de código para a questão 1.}]{../exercicio1/exercicio1.c}

\section{Questão 2}
Uma raiz $\alpha$ de $f(x) = 0$ e dita múltipla de multiplicidade $p$ se $ 0 \neq |g(\alpha)| < \infty, f(x) = (x - \alpha)^{p}g(x)$. Assim, se $\alpha$ é de multiplicidade $p$ então

 \[ f(\alpha) = f'(\alpha) = ... = f^{(p-1)}(\alpha) = 0 \quad e \quad f^{(p)}(\alpha) \neq 0 \]

Vimos que e $\alpha$ é uma raiz múltipla então o método de Newton não converge quadraticamente, mas
sim linearmente com constante assintótica do erro (taxa de convergência) igual a $(1−1/p)$.

a)  Mostre,  com  o  devido  desenvolvimento,  uma  forma  de  recuperar  a  convergência  quadrática  do
método de Newton.

b)  Defina um problema com raiz múltipla, implemente o Método da Bisseção, o Método da Secante,
o método de Newton original e a sua modificação discutida na letra a) e os utilize para calcular a
raiz, mostrando numericamente a taxa e a ordem de convergência obtidas para cada método.

\subsection{}


Uma sequência de iterações $ {x_n / n \geq 0} $ é dita convergente para um ponto $ \alpha $, com
ordem de convergência $ p \geq 1 $ se para algum $ c > 0 $ (taxa de convergência):
\[ |\alpha - x_{n+1}| \leq c \cdot |\alpha - x_n|^p, \quad n \geq 0 \],
ou ainda:
\[ \lim_{n \to \infty} \frac{|\alpha - x_{n+1}|}{|\alpha - x_n|^p} = c \]

Analisando o método de Newton modificado ~\cite[p.~101]{ruggiero} para uma função $ f $ com raiz $ \alpha $ de $ f(x) = 0 $
de multiplicidade $ m $:
\[ x_{n+1} = x_n - m \cdot \frac{f(x_n)}{f'(x_n)} \]
\[ f(\alpha) = f'(\alpha) = ... = f^{(m-1)}(\alpha) = 0 \quad e \quad f^{(m)}(\alpha) \neq 0 \]

Expandindo $ f(x) $ e $ f'(x) $ em torno de $ \alpha $:
\[ f(x) = \cancelto{0}{f(\alpha)} +
          \; \cancelto{0}{ ... } \quad +
          \frac{(x - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
          \frac{(x - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha) +
          \underbrace{O((x - \alpha)^{m+2})}_{\approx 0} \]
\[ f'(x) = \cancelto{0}{f'(\alpha)} +
           (x - \alpha) \cdot \cancelto{0}{f''(\alpha)} +
           \; \cancelto{0}{ ... } \quad +
           \frac{(x - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha) +
           \underbrace{O((x - \alpha)^{m})}_{\approx 0} \]

Avaliando-as então em $ x_n $:
\[ f(x_n) = \frac{(x_n - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
            \frac{(x_n - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha) \]
\[ f'(x_n) = \frac{(x_n - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha) \]

Assim, podemos reescrever $ x_{n+1} - \alpha $ como:
\[ x_{n+1} - \alpha \overset{def.}{=} (x_n - m \cdot \frac{f(x_n)}{f'(x_n)}) - \alpha\]
\[ = x_n - m \cdot
     \frac{\frac{(x_n - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
            \frac{(x_n - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha)}
          {\frac{(x_n - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = x_n - \cancel{m} \cdot \frac{(x_n - \alpha)^{\bcancel{m}} \cdot
     [(m+1) \cdot f^{(m)}(\alpha) + (x_n - \alpha) \cdot f^{(m+1)}(\alpha))]}
     {(m+1)\cancel{\; ! \;}} \cdot \frac{\cancel{(m-1)!}}{\bcancel{(x - \alpha)^{m-1}}
     \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = x_n - \frac{(x_n - \alpha) \cdot [(m+1) \cdot f^{(m)}(\alpha) + (x_n - \alpha)
     \cdot f^{(m+1)}(\alpha))]}{(m+1) \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = \cancel{x_n} - (\cancel{x_n} - \bcancel{\alpha}) - \frac{(x_n - \alpha)^2 \cdot f^{(m+1)}(\alpha)}
     {(m+1) \cdot f^{(m)}(\alpha)} - \bcancel{\alpha}\]
\[ = - (x_n - \alpha)^2 \cdot \frac{f^{(m+1)}(\alpha)}{(m+1) \cdot f^{(m)}(\alpha)}\]

Logo:
\[ | x_{n+1} - \alpha | =  \underbrace{|\frac{f^{(m+1)}(\alpha)}{(m+1) \cdot f^{(m)}(\alpha)}|
                           }_{= \; c} \cdot |x_n - \alpha|^{\overbrace{2}^{= \; p}} \]
\[ \Rightarrow \text{ordem de convergência 2 (convergência quadrática)} \]

Outra forma de modificar o método de Newton ~\cite[p.~353-356]{rabinowitz}, implementada na parte B, é:
\[ x_{n+1} = x_n - \frac{U(x_n)}{U'(x_n)} \text{\; , \; onde \quad} U(x) = \frac{f(x)}{f'(x)} \]

Usando as expansões de $ f $ e $ f' $ calculadas anteriormente com $ A = \frac{f^{(m)(\alpha)}}{m!} \neq 0 $,
$ B = \frac{f^{(m+1)(\alpha)}}{(m+1)!} $ e $ C = \frac{B}{A} $, constantes:
\[ f(x) = A \cdot (x - \alpha)^m + B \cdot (x - \alpha)^{m+1} \]
\[ f'(x) = m \cdot A \cdot (x - \alpha)^{m-1} \]

Substituindo em $ \frac{U(x)}{U'(x)} $:


\[ U(x) = \frac{1}{m} \cdot (x-\alpha) + \frac{B}{m \cdot A} \cdot (x-\alpha)^2, \quad
   U'(x) = \frac{1}{m} + \frac{2B}{m \cdot A} \cdot (x-\alpha) \]
\[ \frac{U(x)}{U'(x)} = \frac
   {\cancel{\frac{1}{m}} \cdot (x-\alpha) \cdot [1 + C \cdot (x-\alpha)]}
   {\cancel{\frac{1}{m}} \cdot [1 + 2C \cdot (x-\alpha)]} \]

Portanto o erro na $(n+1)$-ésima iteração é $ \; e_{n+1} = x_{n+1} - \alpha \overset{def.}{=} x_n - \frac{U(x)}{U'(x)} - \alpha = e_n - \frac{U(x)}{U'(x)}$:
\[ e_{n+1} = e_n - \frac{e_n \cdot (1 + C \cdot e_n)}{(1 + 2C \cdot e_n)} \]
\[ = e_n \cdot ( 1 - \frac{(1 + C \cdot e_n)}{(1 + 2C \cdot e_n)} )
   = e_n \cdot (\frac{C \cdot e_n}{1 + 2C \cdot e_n})\]
\[ = e_n^2 \cdot (\frac{C}{1 + 2C \cdot e_n})\]

Assim, temos que:
\[ \lim_{n \to \infty} \frac{|e_{n+1}|}{|e_n|^2} = \lim_{n \to \infty} |\frac{C}{1 + 2C \cdot e_n}|
   = |C| \cdot \lim_{n \to \infty} \frac{1}{1 + 2|C| \cdot
   \cancel{|\underbrace{x_n}_{\to \; \alpha}- \; \alpha \;|}} = |C| \cdot \lim_{n \to \infty} \frac{1}{1}
   = |C| \]
\[ \therefore \lim_{n \to \infty} \frac{|e_{n+1}|}{|e_n|^2} = |C| \Rightarrow
   \text{ordem de convergência 2 (convergência quadrática)} \]

Concluindo, caso estejamos tratando uma função $ f $ com raiz $ \alpha $ de multiplicidade $ m $, as
seguintes modificações no método de Newton recuperam sua convergência quadrática:
\[ x_{n+1} = x_n - m \cdot \frac{f(x_n)}{f'(x_n)} \]
\[ x_{n+1} = x_n - \frac{U(x_n)}{U'(x_n)} ,  \quad U(x) = \frac{f(x)}{f'(x)} \]

Além disso, como veremos na parte B abaixo, para um polinômio com raízes múltiplas
foram necessárias 9 iterações do método de Newton original, enquanto que com a segunda modificação
apresentada foram necessárias somente 2 iterações para o mesmo ponto inicial.


\subsection{}

Foram implementados os 4 algoritmos pedidos no enunciado, Método da Bisseção, o Método da Secante,
o Método de Newton original e sua modificação (na \texttt{Parte A} dessa questão foram provados duas maneiras
distintas de se obter a convergência quadrática do método de Newton, foi implementada a segunda maneira pois não
depende saber m a priori).

Para exemplificar este exercício foi utilizado um polinômio de raizes múltiplas:

\[ 2x^5 + - 20x^4 + 68x^3 -104x^2 + 74x -20 = 2(x-1)^3(x-2)( x-5)\]

O cálculo da raiz de cada um desses algoritmos está exibido na Listagem~\ref{lst:label3}, assim como
o número de iterações necessárias para convergir. Os métodos da bisseção e secante convergem a taxas menores,
e portanto realizam maior número de iterações. (Adendo: todos os métodos são dependentes dos pontos inicias,
e podem convergir mais rapidamente dependendo destes pontos.) Os métodos de Newton comparados apresentaram uma
diferença significativa em fator de convergência, sendo o método modificado mais que quadraticamente (no caso até cubicamente mais rápido)
 mais rápido para o mesmo ponto inicial.

\begin{lstlisting}[caption= \textbf{Passo a passo de diferentes algoritmos para determinar a raiz de função com raizes múltiplas.},label={lst:label3}]
  Media: 4.5 F_m: -107.1875
  Media: 6.75 F_m: 3160.56835938
  Media: 5.625 F_m: 448.283996582
  Media: 5.0625 F_m: 25.666475296
  Media: 4.78125 F_m: -65.7846035361
  Media: 4.921875 F_m: -27.5399343763
  Media: 4.9921875 F_m: -2.97468937194
  Media: 5.02734375 F_m: 10.8144866157
  Media: 5.009765625 F_m: 3.78982958678
  Media: 5.0009765625 F_m: 0.375396885005
  Media: 4.99658203125 F_m: -1.30764677991
  Media: 4.99877929688 F_m: -0.468130417219
  Media: 4.99987792969 F_m: -0.0468688014225
  Media: 5.00042724609 F_m: 0.164138449422
  Media: 5.00015258789 F_m: 0.0586034363523
  Media: 5.00001525879 F_m: 0.00585947185755
  Media: 4.99994659424 F_m: -0.0205066260205
  Media: 4.99998092651 F_m: -0.0073240674119
  Media: 4.99999809265 F_m: -0.000732420361601
  Media: 5.00000667572 F_m: 0.00256349510164
  Media: 5.00000238419 F_m: 0.000915529709346
  Media: 5.00000023842 F_m: 9.15527575671e-05
  METODO DA BISSECAO
  Achou a raiz: 5.00000023842
  Numero de iteracoes: 22
  -------------------------------
  Media: 0.00627352572146 F_m: -19.5398354788
  Media: 0.272664468156 F_m: -6.28387508792
  Media: 0.398944824875 F_m: -3.19916587126
  Media: 0.529910753606 F_m: -1.36530864458
  Media: 0.627415026044 F_m: -0.620845449741
  Media: 0.708728762294 F_m: -0.273858511139
  Media: 0.772905410655 F_m: -0.121498345517
  Media: 0.824082544553 F_m: -0.0534669661609
  Media: 0.864303485423 F_m: -0.0234718342023
  Media: 0.895777234458 F_m: -0.0102613711505
  Media: 0.92022481204 F_m: -0.00447304307117
  Media: 0.939117152973 F_m: -0.00194447669548
  Media: 0.953645431535 F_m: -0.00084343269782
  Media: 0.96477452829 F_m: -0.000365176821177
  Media: 0.973272255917 F_m: -0.000157879038625
  Media: 0.979744168215 F_m: -6.81778053888e-05
  METODO DA SECANTE
  Achou a raiz: 0.979744168215
  Numero de iteracoes: 16
  -------------------------------
  Media: 0.645161290323 F_m: -0.527208787994
  Media: 0.751292823997 F_m: -0.163234649909
  Media: 0.827637023342 F_m: -0.050096355305
  Media: 0.881697563505 F_m: -0.0152506576222
  Media: 0.919439444395 F_m: -0.00461069390615
  Media: 0.945474617282 F_m: -0.00138619147897
  Media: 0.963263407207 F_m: -0.000414978367587
  Media: 0.97532981075 F_m: -0.000123840254886
  Media: 0.983471233981 F_m: -3.68741353824e-05
  METODO DE NEWTON
  Achou a raiz: 0.983471233981
  Numero de iteracoes: 9
  -------------------------------
  Media: 1.05138339921 F_m: 0.00101632866931
  Media: 1.00120254996 F_m: 1.38914231229e-08
  METODO DE NEWTON PARA RAIZES MULTIPLAS
  Achou a raiz: 1.00120254996
  Numero de iteracoes: 2
  -------------------------------
\end{lstlisting}

\subsection*{Código}

\lstinputlisting[caption=\textbf{Base de código para a questão 2.},language=Python]{../exercicio2/projeto1-2.py}


\section{Questão 3}

Sejam $ A \in \mathbb{R}^{n×n} $ uma matriz inversível, $ \mathbf{b} \in \mathbb{R}^{n} $
um vetor dado e o problema: encontrar $ \mathbf{x} \in \mathbb{R}^{n} $ tal que
\begin{equation}
A\mathbf{x} = \mathbf{b}.
\end{equation}

a) Utilizando como base algum dos diversos algoritmos encontrados nas referencias
bibliográficas, escreva um programa para realizar a fatoração $ A = LU $ e, 
utilizando esta fatoração, resolver o problema $ (1). $
Discuta sua complexidade computacional.

b) Com base no algoritmo da letra a), desenvolva um programa especializado para o caso 
em que a matriz $ A $ é tridiagonal, ou seja $ A = (a_{ij}) $ com $ a_{ij} = 0 $ para 
$ |i − j| > 1 $, discutindo sua complexidade computacional.

c) Utilizando os programas das letras a) e b), resolva o sistema dado por:
\[ −x_{k−1} + 2x_k − x_{k+1} = \frac{8}{(n + 1)^2}, \quad k = 1, 2, . . . , n \]

com $ x_0 = x_{n+1} = 0 $, para vários valores de $ n $ e compare sua solução com a
solução analítica:
\[ x_k = 4 \left[ \frac{k}{n+1} - \left( \frac{k}{n+1} \right)^2 \right]. \]

Discuta o comportamento dos programas para o caso em que $ n $ é grande.

\subsection{}
Avaliando a ordem de operações realizadas pelo algoritmo de fatoração $ A=LU $ (vide 
Listagem \ref{ex3a} linha 4), temos:
\[ n^2 + n^2 + \sum_{j=0}^{n-1} \left[ 
   \sum_{i=0}^{j}\sum_{k=0}^{i}1 + \sum_{i=j}^{n-1}\sum_{k=0}^{j}1
   \right] \in O(n^3) \]

Enquanto que para as funções (análogas) de substituição que serolvem os sistemas
triangulares $ L\mathbf{y} = \mathbf{b} $ e $ U\mathbf{x} = \mathbf{y} $ (linhas 15 e 22 
da Listagem \ref{ex3a}) temos:
\[ n + \sum_{i=0}^{n-1}i \in O(n^2) \]

Portanto o algoritmo tem complexidade computacional $ O(n^3) $.

\subsection{}
Uma vez que só temos valores não nulos nos elementos $ a_{ij} $ com $ |i − j| \leq 1 $,
há $ (3n - 2) $ elementos a serem considerados em uma matriz $ n \times n $.

Assim, utilizando um algoritmo especializadopara uma matriz $ A $
tridiagonal~\cite{barannyk} , a fatoração $ A=LU $ leva $ O(n) $ operações (pois 
podemos realizá-la em apenas um laço, vide Listagem \ref{ex3b} linha 28).

Deste modo, a complexidade computacional do algoritmo passa a ser dominada pelas mesmas 
funções de substituição para frente e para trás utilizadas na parte A, que 
executam $ O(n^2) $ operações para resolver os sistemas triangulares resultantes.

\subsection{}
Como esperado, para todos os valores testados de $ n $ o algoritmo da parte B foi mais rápido que o da parte A (vide Listagem \ref{lst:label4}).

Contudo, notou-se um resultado interessante ao executar-se o código da Listagem \ref{ex3c},
os erros entre a solução analítica do sistema e os algoritmos das partes A e B foram 
iguais, sendo o maior erro de um sistema $ 256 \times 256 $ ($ n = 256 $) da ordem de 
$ e^{-14} \approx 10^{-6} $.

\begin{lstlisting}[caption= \textbf{Razão entre o tempo de execução do algoritmo da 
parte A ($ t_1 $) pelo da parte B ($ t_2 $) para solução do sistema da parte C de tamanho 
$ n \times n $. Média para 10 repetições.},label={lst:label4}]
n == 4
t1/t2 == 1.7712765957446808
n == 16
t1/t2 == 3.4806303348653973
n == 64
t1/t2 == 25.20442779291553
n == 128
t1/t2 == 13.798185149103297
n == 256
t1/t2 == 40.80784523531436
------------------------
n == 4
t1/t2 == 1.6923076923076923
n == 16
t1/t2 == 3.2416938110749185
n == 64
t1/t2 == 9.820340136054421
n == 128
t1/t2 == 6.819929544264985
n == 256
t1/t2 == 41.670446037009306
------------------------
n == 4
t1/t2 == 1.7548209366391185
n == 16
t1/t2 == 3.296
n == 64
t1/t2 == 25.154520547945207
n == 128
t1/t2 == 40.28623791409098
n == 256
t1/t2 == 80.32036298306787
------------------------
n == 4
t1/t2 == 1.8666666666666667
n == 16
t1/t2 == 3.0426758938869667
n == 64
t1/t2 == 9.867851521511017
n == 128
t1/t2 == 7.380226342670431
n == 256
t1/t2 == 40.61159398664528
------------------------
n == 4
t1/t2 == 1.901197604790419
n == 16
t1/t2 == 3.3423076923076924
n == 64
t1/t2 == 24.862773029439698
n == 128
t1/t2 == 40.50711764939133
n == 256
t1/t2 == 43.35305240060278
------------------------
n == 4
t1/t2 == 1.7853107344632768
n == 16
t1/t2 == 3.443097643097643
n == 64
t1/t2 == 23.775139756658994
n == 128
t1/t2 == 37.60842373962986
n == 256
t1/t2 == 41.50932503286756
------------------------
n == 4
t1/t2 == 2.0238095238095237
n == 16
t1/t2 == 3.3963538149898715
n == 64
t1/t2 == 25.566847176313384
n == 128
t1/t2 == 41.207244620184
n == 256
t1/t2 == 42.573204570044155
------------------------
n == 4
t1/t2 == 1.7977207977207976
n == 16
t1/t2 == 3.1312649164677806
n == 64
t1/t2 == 0.36914167185954394
n == 128
t1/t2 == 36.17040019046382
n == 256
t1/t2 == 40.95893771989383
------------------------
n == 4
t1/t2 == 1.8115942028985508
n == 16
t1/t2 == 3.18782722513089
n == 64
t1/t2 == 20.51047473739804
n == 128
t1/t2 == 40.946026061872075
n == 256
t1/t2 == 39.80277838547364
------------------------
n == 4
t1/t2 == 1.8521739130434782
n == 16
t1/t2 == 3.2722044728434505
n == 64
t1/t2 == 24.043363550263834
n == 128
t1/t2 == 40.96217446876498
n == 256
t1/t2 == 42.269799554223745
------------------------
n: t1/t2
4: 1.8256878668084204
16: 3.2834055804664617
64: 18.917487992035966
128: 30.56859656804358
256: 45.38773459051425
\end{lstlisting}

\subsection*{Código}

\lstinputlisting[label={ex3a},caption=\textbf{Base de código para a questão 3.a},language=Python]{../exercicio3/projeto1-3-a.py}

\lstinputlisting[label={ex3b},caption=\textbf{Base de código para a questão 3.b},language=Python]{../exercicio3/projeto1-3-b.py}

\lstinputlisting[label={ex3c},caption=\textbf{Base de código para a questão 3.c},language=Python]{../exercicio3/projeto1-3-c.py}

\bibliographystyle{IEEEtran}
\footnotesize{
\bibliography{projeto-1.bib}
}
\end{document}
