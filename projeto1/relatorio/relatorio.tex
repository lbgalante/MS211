\documentclass[12pt,a4paper,final]{article}
\usepackage[hmargin=2cm,vmargin=2cm,bmargin=2cm]{geometry} % Margem Obrigatoria
\usepackage{pslatex} %times new roman obrigatorio
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage{amsmath}
\usepackage{titling}
%\usepackage[•]{•}kage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
%\graphicspath{{images/}}
%\usepackage{float}
%\usepackage{caption}
\usepackage{floatrow}
\usepackage{multirow}
\usepackage{url}
\usepackage[brazil]{babel} % em portugues brasileiro
\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{color}
\usepackage{cancel}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=t,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=shadowbox,
    tabsize=2
}

\lstset{style=mystyle}
\renewcommand{\lstlistingname}{Listagem}
\newcommand{\blue}{\textcolor{blue}}
\renewcommand{\thesubsection}{\thesection.\Alph{subsection}}
\floatsetup[table]{capposition=top}
\author{Lucas Baganha Galante 182364\\Tiago Loureiro Chaves 187690}

\title{Cálculo Numérico \\ Projeto 1 - Turma D}

\date{2 de Outubro de 2018}

\begin{document}

\onehalfspace %Espaçamento 1.5 obrigatório

\maketitle

% \begin{abstract}
% \end{abstract}

\section{Questão 1}
\textbf{Fazer o projeto 1: ``Precisão da Máquina'',
da página 24 do livro \textit{Cálculo Numérico}, Ruggiero-Lopes, 2a. edição.}

\subsection{}

O algoritmo descrito no exercício foi implementado na linguagem C, por apresentar
variáveis com precisão simples e dupla. A saída contém a precisão de máquina de
cada tipo de variável expressa em 20 casas decimais, como visto na Listagem~\ref{lst:label1}.

\begin{lstlisting}[caption= \textbf{Precisão de máquina para variáveis simples e duplas.},label={lst:label1}]
  The single precision is: 0.00000011920928955078
  The double precision is: 0.00000000000000022204
\end{lstlisting}

A variável com precisão dupla apresenta maior precisão que a variável com precisão
simples; com 16 casas decimais, que compara com 7 casas decimais da precisão simples. Portanto o ganho
é maior que o dobro, como esperado.

\subsection{}

Quando se sai do laço while se perde uma precisão a mais que a precisão de máquina, que é o
motivo para se sair do laço, pois a soma $1+A$ não é maior que $1$, devido a aritmética de ponto
flutuante. Deste modo é necessário multiplicar $A$ por 2, para que se retorne ao menor valor em que
a máquina possui precisão.

\subsection{}

O algoritmo executado na \texttt{Parte A} foi modificado para se utilizar um valor \textbf{VAL} para
inicialização ao invés da referência, o número 1. A saída é vista abaixo na Listagem~\ref{lst:label2}

\begin{lstlisting}[caption= \textbf{Precisão de máquina para diferentes valores VAL.},label={lst:label2}]
  The single precision for VAL:    10.0 is: 0.00000095367431640625
  The single precision for VAL:    17.0 is: 0.00000190734863281250
  The single precision for VAL:   100.0 is: 0.00000762939453125000
  The single precision for VAL:   184.0 is: 0.00001525878906250000
  The single precision for VAL:  1000.0 is: 0.00006103515625000000
  The single precision for VAL:  1575.0 is: 0.00012207031250000000
  The single precision for VAL: 10000.0 is: 0.00097656250000000000
  The single precision for VAL: 17893.0 is: 0.00195312500000000000
\end{lstlisting}

Se percebe da saída que quanto maior o valor de \textbf{VAL} menor se torna
a precisão da máquina. Isso ocorre pois serão necessários
mais dígitos da mantissa para representar na variável de iteração (no algoritmo
atribuída como variável \texttt{s}), o que diminui o número
de dígitos que podem ser usados para determinar a precisão.

\subsection*{Código}

\lstinputlisting[language=C,caption=\textbf{Base de código para a questão 1.}]{../exercicio1/exercicio1.c}

\section{Questão 2}
Uma raiz $\alpha$ de $f(x) = 0$ e dita múltipla de multiplicidade $p$ se $ 0 \neq |g(\alpha)| < \infty, f(x) = (x - \alpha)^{p}g(x)$. Assim, se $\alpha$ é de multiplicidade $p$ então

 \[ f(\alpha) = f'(\alpha) = ... = f^{(p-1)}(\alpha) = 0 \quad e \quad f^{(p)}(\alpha) \neq 0 \]

Vimos que e $\alpha$ é uma raiz múltipla então o método de Newton não converge quadraticamente, mas
sim linearmente com constante assintótica do erro (taxa de convergência) igual a $(1−1/p)$.

a)  Mostre,  com  o  devido  desenvolvimento,  uma  forma  de  recuperar  a  convergência  quadrática  do
método de Newton.

b)  Defina um problema com raiz múltipla, implemente o Método da Bisseção, o Método da Secante,
o método de Newton original e a sua modificação discutida na letra a) e os utilize para calcular a
raiz, mostrando numericamente a taxa e a ordem de convergência obtidas para cada método.

\subsection{}


Uma sequência de iterações $ {x_n / n \geq 0} $ é dita convergente para um ponto $ \alpha $, com
ordem de convergência $ p \geq 1 $ se para algum $ c > 0 $ (taxa de convergência):
\[ |\alpha - x_{n+1}| \leq c \cdot |\alpha - x_n|^p, \quad n \geq 0 \],
ou ainda:
\[ \lim_{n \to \infty} \frac{|\alpha - x_{n+1}|}{|\alpha - x_n|^p} = c \]

Analisando o método de Newton modificado ~\cite[p.~101]{ruggiero} para uma função $ f $ com raiz $ \alpha $ de $ f(x) = 0 $
de multiplicidade $ m $:
\[ x_{n+1} = x_n - m \cdot \frac{f(x_n)}{f'(x_n)} \]
\[ f(\alpha) = f'(\alpha) = ... = f^{(m-1)}(\alpha) = 0 \quad e \quad f^{(m)}(\alpha) \neq 0 \]

Expandindo $ f(x) $ e $ f'(x) $ em torno de $ \alpha $:
\[ f(x) = \cancelto{0}{f(\alpha)} +
          \; \cancelto{0}{ ... } \quad +
          \frac{(x - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
          \frac{(x - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha) +
          \underbrace{O((x - \alpha)^{m+2})}_{\approx 0} \]
\[ f'(x) = \cancelto{0}{f'(\alpha)} +
           (x - \alpha) \cdot \cancelto{0}{f''(\alpha)} +
           \; \cancelto{0}{ ... } \quad +
           \frac{(x - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha) +
           \underbrace{O((x - \alpha)^{m})}_{\approx 0} \]

Avaliando-as então em $ x_n $:
\[ f(x_n) = \frac{(x_n - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
            \frac{(x_n - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha) \]
\[ f'(x_n) = \frac{(x_n - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha) \]

Assim, podemos reescrever $ x_{n+1} - \alpha $ como:
\[ x_{n+1} - \alpha \overset{def.}{=} (x_n - m \cdot \frac{f(x_n)}{f'(x_n)}) - \alpha\]
\[ = x_n - m \cdot
     \frac{\frac{(x_n - \alpha)^m}{m!} \cdot f^{(m)}(\alpha) +
            \frac{(x_n - \alpha)^{(m+1)}}{(m+1)!} \cdot f^{(m+1)}(\alpha)}
          {\frac{(x_n - \alpha)^{(m-1)}}{(m-1)!} \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = x_n - \cancel{m} \cdot \frac{(x_n - \alpha)^{\bcancel{m}} \cdot
     [(m+1) \cdot f^{(m)}(\alpha) + (x_n - \alpha) \cdot f^{(m+1)}(\alpha))]}
     {(m+1)\cancel{\; ! \;}} \cdot \frac{\cancel{(m-1)!}}{\bcancel{(x - \alpha)^{m-1}}
     \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = x_n - \frac{(x_n - \alpha) \cdot [(m+1) \cdot f^{(m)}(\alpha) + (x_n - \alpha)
     \cdot f^{(m+1)}(\alpha))]}{(m+1) \cdot f^{(m)}(\alpha)} - \alpha\]
\[ = \cancel{x_n} - (\cancel{x_n} - \bcancel{\alpha}) - \frac{(x_n - \alpha)^2 \cdot f^{(m+1)}(\alpha)}
     {(m+1) \cdot f^{(m)}(\alpha)} - \bcancel{\alpha}\]
\[ = - (x_n - \alpha)^2 \cdot \frac{f^{(m+1)}(\alpha)}{(m+1) \cdot f^{(m)}(\alpha)}\]

Logo:
\[ | x_{n+1} - \alpha | =  \underbrace{|\frac{f^{(m+1)}(\alpha)}{(m+1) \cdot f^{(m)}(\alpha)}|
                           }_{= \; c} \cdot |x_n - \alpha|^{\overbrace{2}^{= \; p}} \]
\[ \Rightarrow \text{ordem de convergência 2 (convergência quadrática)} \]

Outra forma de modificar o método de Newton ~\cite[p.~353-356]{rabinowitz}, implementada na parte B, é:
\[ x_{n+1} = x_n - \frac{U(x_n)}{U'(x_n)} \text{\; , \; onde \quad} U(x) = \frac{f(x)}{f'(x)} \]

Usando as expansões de $ f $ e $ f' $ calculadas anteriormente com $ A = \frac{f^{(m)(\alpha)}}{m!} \neq 0 $,
$ B = \frac{f^{(m+1)(\alpha)}}{(m+1)!} $ e $ C = \frac{B}{A} $, constantes:
\[ f(x) = A \cdot (x - \alpha)^m + B \cdot (x - \alpha)^{m+1} \]
\[ f'(x) = m \cdot A \cdot (x - \alpha)^{m-1} \]

Substituindo em $ \frac{U(x)}{U'(x)} $:


\[ U(x) = \frac{1}{m} \cdot (x-\alpha) + \frac{B}{m \cdot A} \cdot (x-\alpha)^2, \quad
   U'(x) = \frac{1}{m} + \frac{2B}{m \cdot A} \cdot (x-\alpha) \]
\[ \frac{U(x)}{U'(x)} = \frac
   {\cancel{\frac{1}{m}} \cdot (x-\alpha) \cdot [1 + C \cdot (x-\alpha)]}
   {\cancel{\frac{1}{m}} \cdot [1 + 2C \cdot (x-\alpha)]} \]

Portanto o erro na $(n+1)$-ésima iteração é $ \; e_{n+1} = x_{n+1} - \alpha \overset{def.}{=} x_n - \frac{U(x)}{U'(x)} - \alpha = e_n - \frac{U(x)}{U'(x)}$:
\[ e_{n+1} = e_n - \frac{e_n \cdot (1 + C \cdot e_n)}{(1 + 2C \cdot e_n)} \]
\[ = e_n \cdot ( 1 - \frac{(1 + C \cdot e_n)}{(1 + 2C \cdot e_n)} )
   = e_n \cdot (\frac{C \cdot e_n}{1 + 2C \cdot e_n})\]
\[ = e_n^2 \cdot (\frac{C}{1 + 2C \cdot e_n})\]

Assim, temos que:
\[ \lim_{n \to \infty} \frac{|e_{n+1}|}{|e_n|^2} = \lim_{n \to \infty} |\frac{C}{1 + 2C \cdot e_n}|
   = |C| \cdot \lim_{n \to \infty} \frac{1}{1 + 2|C| \cdot
   \cancel{|\underbrace{x_n}_{\to \; \alpha}- \; \alpha \;|}} = |C| \cdot \lim_{n \to \infty} \frac{1}{1}
   = |C| \]
\[ \therefore \lim_{n \to \infty} \frac{|e_{n+1}|}{|e_n|^2} = |C| \Rightarrow
   \text{ordem de convergência 2 (convergência quadrática)} \]

Concluindo, caso estejamos tratando uma função $ f $ com raiz $ \alpha $ de multiplicidade $ m $, as
seguintes modificações no método de Newton recuperam sua convergência quadrática:
\[ x_{n+1} = x_n - m \cdot \frac{f(x_n)}{f'(x_n)} \]
\[ x_{n+1} = x_n - \frac{U(x_n)}{U'(x_n)} ,  \quad U(x) = \frac{f(x)}{f'(x)} \]

Além disso, como veremos na parte B abaixo, para um polinômio com raízes múltiplas
foram necessárias 9 iterações do método de Newton original, enquanto que com a segunda modificação
apresentada foram necessárias somente 2 iterações para o mesmo ponto inicial.


\subsection{}

Foram implementados os 4 algoritmos pedidos no enunciado, Método da Bisseção, o Método da Secante,
o Método de Newton original e sua modificação (na \texttt{Parte A} dessa questão foram provados duas maneiras
distintas de se obter a convergência quadrática do método de Newton, foi implementada a segunda maneira pois não
depende saber m a priori).

Para exemplificar este exercício foi utilizado um polinômio de raizes múltiplas:

\[ 2x^5 + - 20x^4 + 68x^3 -104x^2 + 74x -20 = 2(x-1)^3(x-2)( x-5)\]

O cálculo da raiz de cada um desses algoritmos está exibido na Listagem~\ref{lst:label3}, assim como
o número de iterações necessárias para convergir. Os métodos da bisseção e secante convergem a taxas menores,
e portanto realizam maior número de iterações. (Adendo: todos os métodos são dependentes dos pontos inicias,
e podem convergir mais rapidamente dependendo destes pontos.) Os métodos de Newton comparados apresentaram uma
diferença significativa em fator de convergência, sendo o método modificado mais que quadraticamente (no caso até cubicamente mais rápido)
 mais rápido para o mesmo ponto inicial.

\begin{lstlisting}[caption= \textbf{Passo a passo de diferentes algoritmos para determinar a raiz de função com raizes múltiplas.},label={lst:label3}]
  Media: 4.5 F_m: -107.1875
  Media: 6.75 F_m: 3160.56835938
  Media: 5.625 F_m: 448.283996582
  Media: 5.0625 F_m: 25.666475296
  Media: 4.78125 F_m: -65.7846035361
  Media: 4.921875 F_m: -27.5399343763
  Media: 4.9921875 F_m: -2.97468937194
  Media: 5.02734375 F_m: 10.8144866157
  Media: 5.009765625 F_m: 3.78982958678
  Media: 5.0009765625 F_m: 0.375396885005
  Media: 4.99658203125 F_m: -1.30764677991
  Media: 4.99877929688 F_m: -0.468130417219
  Media: 4.99987792969 F_m: -0.0468688014225
  Media: 5.00042724609 F_m: 0.164138449422
  Media: 5.00015258789 F_m: 0.0586034363523
  Media: 5.00001525879 F_m: 0.00585947185755
  Media: 4.99994659424 F_m: -0.0205066260205
  Media: 4.99998092651 F_m: -0.0073240674119
  Media: 4.99999809265 F_m: -0.000732420361601
  Media: 5.00000667572 F_m: 0.00256349510164
  Media: 5.00000238419 F_m: 0.000915529709346
  Media: 5.00000023842 F_m: 9.15527575671e-05
  METODO DA BISSECAO
  Achou a raiz: 5.00000023842
  Numero de iteracoes: 22
  -------------------------------
  Media: 0.00627352572146 F_m: -19.5398354788
  Media: 0.272664468156 F_m: -6.28387508792
  Media: 0.398944824875 F_m: -3.19916587126
  Media: 0.529910753606 F_m: -1.36530864458
  Media: 0.627415026044 F_m: -0.620845449741
  Media: 0.708728762294 F_m: -0.273858511139
  Media: 0.772905410655 F_m: -0.121498345517
  Media: 0.824082544553 F_m: -0.0534669661609
  Media: 0.864303485423 F_m: -0.0234718342023
  Media: 0.895777234458 F_m: -0.0102613711505
  Media: 0.92022481204 F_m: -0.00447304307117
  Media: 0.939117152973 F_m: -0.00194447669548
  Media: 0.953645431535 F_m: -0.00084343269782
  Media: 0.96477452829 F_m: -0.000365176821177
  Media: 0.973272255917 F_m: -0.000157879038625
  Media: 0.979744168215 F_m: -6.81778053888e-05
  METODO DA SECANTE
  Achou a raiz: 0.979744168215
  Numero de iteracoes: 16
  -------------------------------
  Media: 0.645161290323 F_m: -0.527208787994
  Media: 0.751292823997 F_m: -0.163234649909
  Media: 0.827637023342 F_m: -0.050096355305
  Media: 0.881697563505 F_m: -0.0152506576222
  Media: 0.919439444395 F_m: -0.00461069390615
  Media: 0.945474617282 F_m: -0.00138619147897
  Media: 0.963263407207 F_m: -0.000414978367587
  Media: 0.97532981075 F_m: -0.000123840254886
  Media: 0.983471233981 F_m: -3.68741353824e-05
  METODO DE NEWTON
  Achou a raiz: 0.983471233981
  Numero de iteracoes: 9
  -------------------------------
  Media: 1.05138339921 F_m: 0.00101632866931
  Media: 1.00120254996 F_m: 1.38914231229e-08
  METODO DE NEWTON PARA RAIZES MULTIPLAS
  Achou a raiz: 1.00120254996
  Numero de iteracoes: 2
  -------------------------------
\end{lstlisting}

\subsection*{Código}

\lstinputlisting[caption=\textbf{Base de código para a questão 2.},language=Python]{../exercicio2/projeto1-2.py}


\section{Questão 3}

Sejam $ A \in \mathbb{R}^{n×n} $ uma matriz inversível, $ \mathbf{b} \in \mathbb{R}^{n} $
um vetor dado e o problema: encontrar $ \mathbf{x} \in \mathbb{R}^{n} $ tal que
\begin{equation}
A\mathbf{x} = \mathbf{b}.
\end{equation}

a) Utilizando como base algum dos diversos algoritmos encontrados nas referencias
bibliográficas, escreva um programa para realizar a fatoração $ A = LU $ e, 
utilizando esta fatoração, resolver o problema $ (1). $
Discuta sua complexidade computacional.

b) Com base no algoritmo da letra a), desenvolva um programa especializado para o caso 
em que a matriz $ A $ é tridiagonal, ou seja $ A = (a_{ij}) $ com $ a_{ij} = 0 $ para 
$ |i − j| > 1 $, discutindo sua complexidade computacional.

c) Utilizando os programas das letras a) e b), resolva o sistema dado por:
\[ −x_{k−1} + 2x_k − x_{k+1} = \frac{8}{(n + 1)^2}, \quad k = 1, 2, . . . , n \]

com $ x_0 = x_{n+1} = 0 $, para vários valores de $ n $ e compare sua solução com a
solução analítica:
\[ x_k = 4 \left[ \frac{k}{n+1} - \left( \frac{k}{n+1} \right)^2 \right]. \]

Discuta o comportamento dos programas para o caso em que $ n $ é grande.

\subsection{}

\subsection{}

\subsection*{Código}


\bibliographystyle{IEEEtran}
\footnotesize{
\bibliography{projeto-1.bib}
}
\end{document}
